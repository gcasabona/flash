#!/bin/bash
#----------------------------------------------------
# Example SLURM job script to run MPI applications on 
# TACC's Stampede system.
# 
# $Id: job.mpi 1580 2013-01-08 04:10:50Z karl $
#----------------------------------------------------
#
#SBATCH -J tar_512_10^6_1.0_newburn_burning              # Job name
#SBATCH -o tar_512_10^6_1.0_newburn_burning.%j.out       # Name of stdout output file (%j expands to jobId)
#SBATCH -p normal                 #Queue name
#SBATCH -N 1                     #Total number of nodes requested (64 cores/node)
#SBATCH --mail-user=gcasabona@umassd.edu # Set e-mail address
#SBATCH --mail-type=all       # mail at beginning and end of job
#SBATCH -n 64                 # Total number of mpi tasks requested
#SBATCH -t 30:00:00           # Run time (hh:mm:ss) - 0.5 hours
#
#SBATCH -A TG-AST100038       # <-- Allocation name to charge job against
#
# Go into the directory containing the executable
#
cd /home1/05351/casabona 
#
# Launch the MPI executable named "flash4"
#
python ranch_transfer.py /scratch/05351/casabona/stirturb/helium/512/rho_10^6/he_1.0/new_burnF90/burning /scratch/05351/casabona/stirturb/helium/512/rho_10^6/he_1.0/new_burnF90/burning/tar   stirturbhelm_512_10^6_1.0_newburn_burning 30
 

